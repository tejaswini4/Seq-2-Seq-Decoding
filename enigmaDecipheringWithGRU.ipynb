{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"enigmaDecipheringWithGRU.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMfbKFkNa1BSuCAXO/t/s7Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sMCnY_2qYSmO","colab_type":"text"},"source":["# **Enigma Deciphering with GRU**\n","In this code, I am deciphering the enigma encoding for a fixed configuration. I am using GRU to achieve this. This problem comes under seq-seq model.\n","\n","### **Brief Background of Enigma**\n","Enigma is an encryption device that played some role during world war II. The way enigma works is that it encrypts a character into some other charcater based on the machine's mechanical configuration which would change after every press on the keyboard.\n","\n","In this problem, I am using a static configuration of the machine rather than the dynamic configuration to keep things simple. But it should be noted that this machine has some time dependency that is the character that it encodes to is based on the previous character. \n","\n","### **Data Generation**\n","I am generating the data using faker and enigmaMachine.\n"]},{"cell_type":"code","metadata":{"id":"_WtZhbhbYZHI","colab_type":"code","outputId":"103e769a-eab3-4d26-ae09-37580ef73194","executionInfo":{"status":"ok","timestamp":1585158491817,"user_tz":360,"elapsed":4630,"user":{"displayName":"tejaswini kancharla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMqaTLWhZDYuqt5eEYOxf1qnuofS3ykWLKvCh8kw=s64","userId":"16813545254596419714"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["!pip install py-enigma ## Installing the library that simulates the enigma machine"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting py-enigma\n","  Downloading https://files.pythonhosted.org/packages/91/4e/44327ad4a5960de12d86d39e1797f3ab67396a17d82182e8fc1b5ef347e5/py-enigma-0.1.tar.gz\n","Building wheels for collected packages: py-enigma\n","  Building wheel for py-enigma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-enigma: filename=py_enigma-0.1-cp36-none-any.whl size=46860 sha256=2a5c3d92f5e6895af3b5e0d09455fc3b8281290ce5e350c8e09f56cb12284cf3\n","  Stored in directory: /root/.cache/pip/wheels/35/5b/fb/f29b74ef2508b1cd3fa78ba14f57888e0a8488daed8672c4cf\n","Successfully built py-enigma\n","Installing collected packages: py-enigma\n","Successfully installed py-enigma-0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8wWNnqXrkKKy","colab_type":"code","outputId":"80393aa4-9870-41af-8545-1a1925e55e69","executionInfo":{"status":"ok","timestamp":1585158596178,"user_tz":360,"elapsed":3555,"user":{"displayName":"tejaswini kancharla","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMqaTLWhZDYuqt5eEYOxf1qnuofS3ykWLKvCh8kw=s64","userId":"16813545254596419714"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["!pip install Faker ## Library that generates fake data"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting Faker\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/6f/2a868e12996ea630a4591aa967cb934e411d94e42da12e1dd141b66d0070/Faker-4.0.2-py3-none-any.whl (1.0MB)\n","\r\u001b[K     |▎                               | 10kB 31.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 440kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 450kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 460kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 471kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 481kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 491kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 501kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 512kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 522kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 532kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 542kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 552kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 563kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 573kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 583kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 593kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 604kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 614kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 624kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 634kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 645kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 655kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 665kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 675kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 686kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 696kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 706kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 716kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 727kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 737kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 747kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 757kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 768kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 778kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 788kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 798kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 808kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 819kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 829kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 839kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 849kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 860kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 870kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 880kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 890kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 901kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 911kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 921kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 931kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 942kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 952kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 962kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 972kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 983kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 993kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from Faker) (2.8.1)\n","Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.6/dist-packages (from Faker) (1.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.4->Faker) (1.12.0)\n","Installing collected packages: Faker\n","Successfully installed Faker-4.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zeEF_Dp46pOy","colab_type":"code","colab":{}},"source":["from typing import List, Tuple\n","from enigma.machine import EnigmaMachine\n","from faker import Faker\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJlYTmqD6rbT","colab_type":"code","colab":{}},"source":["from google.colab import files"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E27d2zQI6txb","colab_type":"code","colab":{}},"source":["### This is the virtual enigma machine with a certain configuration we would be using for this code\n","class ConfiguredMachine:\n","    def __init__(self):\n","        self.machine = EnigmaMachine.from_key_sheet(\n","            rotors='II IV V',\n","            reflector='B',\n","            ring_settings=[1, 20, 11],\n","            plugboard_settings='AV BS CG DL FU HZ IN KM OW RX')\n","\n","    def reset(self):\n","        self.machine.set_display('WXC')\n","\n","    def encode(self, plain_str: str) -> str:\n","        self.reset()\n","        return self.machine.process_text(plain_str)\n","\n","    def batch_encode(self, plain_list: List[str]) -> List[str]:\n","        encoded = list()\n","        for s in plain_list:\n","            encoded.append(self.encode(s))\n","        return encoded"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9mgbsg46wIl","colab_type":"code","colab":{}},"source":["### preprocessing the text generated by faker to eliminate punctuation and converting to uppercase just to keep things clean and simple\n","def pre_process(input_str):\n","    return re.sub('[^a-zA-Z]', '', input_str).upper()\n","\n","\n","def generate_data(batch_size: int, seq_len: int = 42) -> Tuple[List[str], List[str]]:\n","    fake = Faker()\n","    machine = ConfiguredMachine()\n","\n","    plain_list = fake.texts(nb_texts=batch_size, max_nb_chars=seq_len)\n","    plain_list = [pre_process(p) for p in plain_list]\n","    cipher_list = machine.batch_encode(plain_list)\n","    return plain_list, cipher_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pyu2q728d4l7","colab_type":"code","colab":{}},"source":["import collections\n","import helper\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Model\n","from keras.layers import LSTM, GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n","from keras.layers.embeddings import Embedding\n","from keras.optimizers import Adam\n","from keras.losses import sparse_categorical_crossentropy\n","from keras.preprocessing.sequence import pad_sequences\n","\n","#### Initializing the basic stuff\n","input_characters=['','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n","input_characters=target_characters=sorted(list(input_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","\n","\n","input_token_index = dict(\n","  [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","  [(i,char) for i, char in enumerate(target_characters)])\n","\n","\n","### Helper Functions\n","def tokenize(x):\n","  tokenized_text=[]\n","  for c in x:\n","    tokenized_text.append(input_token_index[c])\n","  return (tokenized_text)\n","\n","def preprocess(cipher,plain):\n","  cipher_sentences, plain_sentences=[],[]\n","  for c,p in zip(cipher,plain):\n","    cipher_sentences.append(tokenize(c))\n","    plain_sentences.append(tokenize(p))\n","  cipher_sentences=pad_sequences(cipher_sentences, maxlen=42, padding='post')\n","  plain_sentences=pad_sequences(plain_sentences, maxlen=42, padding='post')\n","  plain_sentences= plain_sentences.reshape(*plain_sentences.shape, 1)\n","  return cipher_sentences,plain_sentences\n","\n","def logits_to_text(logits, target_token_index):\n","    return ''.join([target_token_index[prediction] for prediction in np.argmax(logits, 1)])\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NnjgzkghhTfV","colab_type":"text"},"source":["# Cells below are to build and train a model. "]},{"cell_type":"code","metadata":{"id":"rrL8PB-e6124","colab_type":"code","colab":{}},"source":["### Building Data to train\n","plain,cipher=generate_data(400000)\n","preproc_cipher, preproc_plain=preprocess(cipher,plain)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCF_eix87WEM","colab_type":"code","colab":{}},"source":["def build_model(input_shape, output_sequence_length, num_encoder_tokens, num_decoder_tokens):\n","    learning_rate=1e-3\n","\n","    input_seq = Input(input_shape[1:])\n","    emb = Embedding(num_encoder_tokens, 64, input_length=output_sequence_length)(input_seq)\n","    bdrnn = Bidirectional(GRU(64, return_sequences=True))(emb)\n","    logits = TimeDistributed(Dense(num_decoder_tokens, activation='softmax'))(bdrnn)\n","\n","    model = Model(inputs=input_seq, outputs=logits)\n","    model.compile(loss=sparse_categorical_crossentropy,\n","                  optimizer=Adam(learning_rate),\n","                  metrics=['accuracy'])\n","    return model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCL4VrHlbOIM","colab_type":"code","outputId":"c829d121-b6eb-4428-c73a-1863c237dd71","executionInfo":{"status":"ok","timestamp":1581881932627,"user_tz":420,"elapsed":826,"user":{"displayName":"tejaswini kancharla","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5L6T7OgPWU2sJeol0Wt_4HdLiq3ShQy3Gvoi83A=s64","userId":"16813545254596419714"}},"colab":{"base_uri":"https://localhost:8080/","height":213}},"source":["emb_bdrnn = build_model(\n","    preproc_cipher.shape,\n","    42,\n","    num_encoder_tokens,\n","    num_decoder_tokens)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ymgd7syTTCIB","colab_type":"code","outputId":"d84f6aff-a805-4f0d-8933-50ca2cf2b48b","executionInfo":{"status":"ok","timestamp":1581882773430,"user_tz":420,"elapsed":838492,"user":{"displayName":"tejaswini kancharla","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD5L6T7OgPWU2sJeol0Wt_4HdLiq3ShQy3Gvoi83A=s64","userId":"16813545254596419714"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print('Final Model Loaded')\n","# Train\n","emb_bdrnn.fit(preproc_cipher, preproc_plain, batch_size=1024, epochs=23, validation_split=0.2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Final Model Loaded\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 320000 samples, validate on 80000 samples\n","Epoch 1/23\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","320000/320000 [==============================] - 39s 122us/step - loss: 1.7673 - acc: 0.4952 - val_loss: 1.4736 - val_acc: 0.5475\n","Epoch 2/23\n","320000/320000 [==============================] - 37s 116us/step - loss: 1.3301 - acc: 0.5913 - val_loss: 1.1254 - val_acc: 0.6569\n","Epoch 3/23\n","320000/320000 [==============================] - 37s 114us/step - loss: 0.8782 - acc: 0.7344 - val_loss: 0.6669 - val_acc: 0.8021\n","Epoch 4/23\n","320000/320000 [==============================] - 37s 115us/step - loss: 0.5164 - acc: 0.8512 - val_loss: 0.4035 - val_acc: 0.8880\n","Epoch 5/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.3342 - acc: 0.9091 - val_loss: 0.2780 - val_acc: 0.9265\n","Epoch 6/23\n","320000/320000 [==============================] - 37s 115us/step - loss: 0.2373 - acc: 0.9386 - val_loss: 0.2035 - val_acc: 0.9488\n","Epoch 7/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.1804 - acc: 0.9547 - val_loss: 0.1579 - val_acc: 0.9611\n","Epoch 8/23\n","320000/320000 [==============================] - 36s 114us/step - loss: 0.1408 - acc: 0.9659 - val_loss: 0.1255 - val_acc: 0.9701\n","Epoch 9/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.1126 - acc: 0.9736 - val_loss: 0.1010 - val_acc: 0.9766\n","Epoch 10/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.0911 - acc: 0.9793 - val_loss: 0.0820 - val_acc: 0.9819\n","Epoch 11/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.0747 - acc: 0.9836 - val_loss: 0.0674 - val_acc: 0.9858\n","Epoch 12/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.0617 - acc: 0.9870 - val_loss: 0.0560 - val_acc: 0.9885\n","Epoch 13/23\n","320000/320000 [==============================] - 37s 114us/step - loss: 0.0512 - acc: 0.9897 - val_loss: 0.0478 - val_acc: 0.9904\n","Epoch 14/23\n","320000/320000 [==============================] - 36s 114us/step - loss: 0.0427 - acc: 0.9918 - val_loss: 0.0392 - val_acc: 0.9925\n","Epoch 15/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0360 - acc: 0.9933 - val_loss: 0.0330 - val_acc: 0.9940\n","Epoch 16/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0306 - acc: 0.9945 - val_loss: 0.0282 - val_acc: 0.9950\n","Epoch 17/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0259 - acc: 0.9955 - val_loss: 0.0239 - val_acc: 0.9959\n","Epoch 18/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.0220 - acc: 0.9963 - val_loss: 0.0217 - val_acc: 0.9962\n","Epoch 19/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0188 - acc: 0.9970 - val_loss: 0.0175 - val_acc: 0.9972\n","Epoch 20/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0160 - acc: 0.9975 - val_loss: 0.0150 - val_acc: 0.9976\n","Epoch 21/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0137 - acc: 0.9979 - val_loss: 0.0129 - val_acc: 0.9980\n","Epoch 22/23\n","320000/320000 [==============================] - 36s 112us/step - loss: 0.0117 - acc: 0.9983 - val_loss: 0.0109 - val_acc: 0.9984\n","Epoch 23/23\n","320000/320000 [==============================] - 36s 113us/step - loss: 0.0100 - acc: 0.9986 - val_loss: 0.0093 - val_acc: 0.9987\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f278e62c160>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"0cFS4vPvwWs6","colab_type":"code","colab":{}},"source":["def decipher(cipher):\n","  cipher_sentences=[]\n","  plain_predictions=[]\n","  for c in cipher:\n","    cipher_sentences.append(tokenize(c))\n","  cipher_sentences=pad_sequences(cipher_sentences, maxlen=42, padding='post')\n","  for i in range(len(cipher_sentences)-1):\n","    p=logits_to_text(emb_bdrnn.predict(cipher_sentences[i:i+1])[0], target_token_index)\n","    plain_predictions.append(p.split()[0])\n","  return(plain_predictions)\n","\n","\n","def predict(cipher_list: List[str]) -> List[str]:\n","    plain_list=decipher(cipher_list) \n","    return plain_list\n","\n","\n","def str_score(str_a: str, str_b: str) -> float:\n","    if len(str_a) != len(str_b):\n","        return 0\n","\n","    n_correct = 0\n","\n","    for a, b in zip(str_a, str_b):\n","        n_correct += int(a == b)\n","\n","    return n_correct / len(str_a)\n","\n","\n","def score(predicted_plain: List[str], correct_plain: List[str]) -> float:\n","    correct = 0\n","    for p, c in zip(predicted_plain, correct_plain):\n","        # print(p.split()[0],len(p),c,len(c))\n","        # print(p,c)\n","        if str_score(p, c) > 0.8:\n","            correct += 1\n","\n","    return correct / len(correct_plain)\n","\n","# Runs the deciphering on \n","if __name__ == \"__main__\":\n","    plain, cipher = generate_data(1<<14)\n","    print(score(predict(cipher), plain))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y2crTiJqSmFs","colab_type":"code","colab":{}},"source":["emb_bdrnn.save(\"enigmaDeciphering.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ1kV37BZLXx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}